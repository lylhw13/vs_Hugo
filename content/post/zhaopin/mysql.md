---
title: "Mysql"
date: 2020-06-14T12:01:18+08:00
draft: true
---

# 编码
如果你在使用 MySQL 或 MariaDB，不要用“utf8”编码，改用“utf8mb4”
- MySQL 的“utf8mb4”是真正的“UTF-8”，支持每个字符最多四个字节。
- MySQL 的“utf8”是一种“专属的编码”，它能够编码的 Unicode 字符并不多, 只支持每个字符最多三个字节。

# 慢索引分析
慢查询分析步骤：
1. 开启slowlog，提取慢查询
2. 仔细分析 explain 中的 type 字段以及 extra 字段

type 字段：提供了判断查询是否高效的依据。通过type字段可以知道此次查询的扫描类型。以下速度依次降低
  - const 表示主键索引
  - range 表示使用索引范围查询
  - index 表示全索引扫描，类似all，但是只扫描索引，不扫描数据
  - all 表示全表扫描
  
key 此次查询中确切用到的索引
rows 扫描读取的行数，原则越少越好
extra 额外的字段

   
MySQL慢查询就是在日志中记录运行比较慢的SQL语句，这个功能需要开启才能用。

在MySQL的配置文件my.cnf中写上：
```txt
long_query_time = 10      # 超过该值，被记录下来（秒）
log-slow-queries = /var/lib/mysql/mysql-slow.log  //指定写入位置
```
这是一个非常有用的日志。它对于性能的影响不大（假设所有查询都很快），并且强调了那些最需要注意的查询（丢失了索引或索引没有得到最佳应用）


电话号码就像地址，只是以数字的形式呈现出来，存储成varchar类型以后，方面正则匹配，格式化，和一般的字符化处理。Strings & VARCHAR.

# 数据库三大范式

1．第一范式(确保每列保持原子性)
2．第二范式(确保表中的每列都和主键相关)
3．第三范式(确保每列都和主键列直接相关,而不是间接相关)


# 缩写
MySQL 数据操作 DML（增删改查）DML（Data Manipulation Language 数据操纵语言）

SQL四种语言：DDL,DML,DCL,TCL
1.DDL（Data Definition Language）数据库定义语言statements are used to define the database structure or schema.

DDL是SQL语言的四大功能之一。
用于定义数据库的三级结构，包括外模式、概念模式、内模式及其相互之间的映像，定义数据的完整性、安全控制等约束
DDL不需要commit.
CREATE
ALTER
DROP
TRUNCATE
COMMENT
RENAME

2.DML（Data Manipulation Language）数据操纵语言statements are used for managing data within schema objects.

由DBMS提供，用于让用户或程序员使用，实现对数据库中数据的操作。
DML分成交互型DML和嵌入型DML两类。
依据语言的级别，DML又可分成过程性DML和非过程性DML两种。
需要commit.
SELECT
INSERT
UPDATE
DELETE
MERGE
CALL
EXPLAIN PLAN
LOCK TABLE

3.DCL（Data Control Language）数据库控制语言  授权，角色控制等
GRANT 授权
REVOKE 取消授权

4.TCL（Transaction Control Language）事务控制语言
SAVEPOINT 设置保存点
ROLLBACK  回滚
SET TRANSACTION

SQL主要分成四部分：
（1）数据定义。（SQL DDL）用于定义SQL模式、基本表、视图和索引的创建和撤消操作。
（2）数据操纵。（SQL DML）数据操纵分成数据查询和数据更新两类。数据更新又分成插入、删除、和修改三种操作。
（3）数据控制。包括对基本表和视图的授权，完整性规则的描述，事务控制等内容。
（4）嵌入式SQL的使用规定。涉及到SQL语句嵌入在宿主语言程序中使用的规则。

多版本并发控制 (Multiversion concurrency control)


# mysql 有那些存储引擎，有哪些区别
InnoDB ：如果要提供提交、回滚、崩溃恢复能力的事务安全（ACID兼容）能力，并要求实现并发控制，InnoDB是一个好的选择.
InnoDB 和 MyISAM之间的区别：
1. InnoDB支持事务，而MyISAM不支持
2. InnoDB支持行级锁，而MyISAM支持表级锁
3. InnoDB支持MVCC, 而MyISAM不支持
4. InnoDB支持外键，而MyISAM不支持
5. InnoDB支持崩溃恢复，而MyISAM不支持
6. InnoDB不支持全文索引，而MyISAM支持

MyISAM：如果数据表主要用来插入和查询记录，则MyISAM（但是不支持事务）引擎能提供较高的处理效率

Memory：如果只是临时存放数据，数据量不大，并且不需要较高的数据安全性，可以选择将数据保存在内存中的Memory引擎，MySQL中使用该引擎作为临时表，存放查询的中间结果。数据的处理速度很快但是安全性不高。

# mysql 索引在什么情况下会失效
- 索引本身失效：比如更改表
- 对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。如：条件字段函数操作，隐式类型转换，隐式字符编码转换，对索引列进行运算
- 跳过索引中的列。最佳左前缀法则——如果索引了多列，要遵守最左前缀法则。指的是查询要从索引的最左前列开始并且不跳过索引中的列。
- 如果条件中有or
- like查询是以通配符%开头
- 在MYSQL使用不等于（<,>,!=）的时候无法使用索引，会导致索引失效。
- is null或者is not null 也会导致无法使用索引。

# mysql 索引模型
常见的有哈希表、有序数组和搜索树
- 哈希表这种结构适用于只有等值查询的场景，对于区间查询是无法直接通过索引查询的，就需要全表扫描。
- 有序数组在等值查询和范围查询场景中的性能就都非常优秀，但如果需要更新代价太高，因此有序数组索引只适用于静态存储引擎
- InnoDB 使用了 B+ 树索引模型，所以数据都是存储在 B+ 树中的。每一个索引在 InnoDB 里面对应一棵 B+ 树。由于在读写上的性能优点，以及适配磁盘的访问模式，已经被广泛应用在数据库引擎中了。在 MySQL 中，索引是在存储引擎层实现的。

# mysql 索引类型
根据叶子节点的内容，索引类型分为主键索引和非主键索引。
- 主键索引的叶子节点存的是整行数据。在 InnoDB 里，`主键索引也被称为聚簇索引（clustered index）`。
- 非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引（secondary index）。由于 InnoDB 是索引组织表，一般情况下建议你创建一个自增主键，这样非主键索引占用的空间最小。

非主键索引需要先得到主键的值，再通过主键索引取得数据内容（回到主键索引树搜索的过程，称为回表）。因此基于非主键索引的查询需要多扫描一棵索引树。我们在应用中应该尽量使用主键查询。

# mysql 索引优化

1. 覆盖索引：如果一个索引包含（或者说覆盖）所有需要查询的字段值，我们称为覆盖索引。覆盖索引不需要回表，可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。
2. 最左前缀：B+ 树这种索引结构，可以利用索引的“最左前缀”，来定位记录。只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符。
   第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。所以当我们创建一个联合索引的时候，如(key1,key2,key3)，相当于创建了（key1）、(key1,key2)和(key1,key2,key3)三个索引，这就是最左匹配原则。
3. 索引下推：MySQL 5.6 引入的索引下推优化（index condition pushdown)，可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。

# mysql 主从同步
一个事务日志同步的完整过程是这样的：
1. 在备库 B 上通过 change master 命令，设置主库 A 的 IP、端口、用户名、密码，以及要从哪个位置开始请求 binlog，这个位置包含文件名和日志偏移量。
2. 在备库 B 上执行 start slave 命令，这时候备库会启动两个线程，就是图中的 io_thread 和 sql_thread。其中 io_thread 负责与主库建立连接。
3. 主库 A 校验完用户名、密码后，开始按照备库 B 传过来的位置，从本地读取 binlog，发给 B。
4. 备库 B 拿到 binlog 后，写到本地文件，称为中转日志（relay log）。
5. sql_thread 读取中转日志，解析出日志里的命令，并执行。

在满足数据可靠性的前提下，MySQL 高可用系统的可用性，是依赖于主备延迟的。延迟的时间越小，在主库故障的时候，服务恢复需要的时间就越短，可用性就越高。

一主多从的设置，一般用于读写分离，主库负责所有的写入和一部分读，其他的读请求则由从库分担。

数据库的多版本并发控制（MVCC, Multiversion concurrency control）

# undo log，redo log 和 binlog 之间的区别：
- undo log 和 redo log是InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。
- redo log是 物理日志， undo log 和 binlog 是逻辑日志。
- redo log 记录的是“在某个数据页上做了什么修改”；binlog 记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”；undo log记录的是具有相反逻辑的sql。
- redo log 是循环写的，空间固定会用完；binlog 和 undo log是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。
- redo log 适用于崩溃恢复(crash-safe), binlog 适用于主从复制和数据恢复； undo log 主要用来实现回滚和mvcc的。

- 当执行rollback时，就可以从undo log中的逻辑记录读取到相应的内容并进行回滚。
- 应用到行版本控制的时候，当读取的某一行被其他事务锁定时，它可以从undo log中分析出该行记录以前的数据是什么，从而提供该行版本信息，让用户实现非锁定一致性读取。
  
事务在执行过程中会不断写入redo log buffer，然后满足策略（三个策略供选择：交给master thread；buffer只剩一半的空间；事务提交）的时候会写入redo log file，以及提交的时候会写入binlog。

Binlog有两种模式，statement 格式的话是记sql语句， row格式会记录行的内容，记两条，更新前和更新后都有。

# binlog还不能去掉:
- 一个原因是，redolog只有InnoDB有，别的引擎没有。
- 另一个原因是，redolog是循环写的，不持久保存，binlog的“归档”这个功能，redolog是不具备的。

# 为什么日志需要“两阶段提交”
将 redo log 的写入拆成了两个步骤：prepare 和 commit，中间写binlog，这就是"两阶段提交"。
由于 redo log 和 binlog 是两个独立的逻辑，如果不用两阶段提交，要么就是先写完 redo log 再写 binlog，或者采用反过来的顺序，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。
redo log 和 binlog 都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。

- redo log 用于保证 crash-safe 能力。innodb_flush_log_at_trx_commit 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。这个参数我建议你设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失。
- sync_binlog 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。这个参数我也建议你设置成 1，这样可以保证 MySQL 异常重启之后 binlog 不丢失。

# Mysql里有两个视图的概念：
- 一个是 view。它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果。创建视图的语法是 create view … ，而它的查询方法与表一样。
- 另一个是 InnoDB 在实现 MVCC 时用到的一致性读视图，即 consistent read view，用于支持 RC（Read Committed，读提交）和 RR（Repeatable Read，可重复读）隔离级别的实现。

在可重复读隔离级别下，事务在启动的时候就“拍了个快照”。注意，这个快照是基于整库的。
InnoDB 利用了“所有数据都有多个版本”的这个特性，实现了“秒级创建快照”的能力。

InnoDB 里面每个事务有一个唯一的事务 ID，叫作 transaction id。它是在事务开始的时候向 InnoDB 的事务系统申请的，是按申请顺序严格递增的。
而每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把 transaction id 赋值给这个数据版本的事务 ID，记为 row trx_id。同时，旧的数据版本要保留，并且在新的数据版本中，能够有信息可以直接拿到它。也就是说，数据表中的一行记录，其实可能有多个版本 (row)，每个版本有自己的 row trx_id。
一个事务只需要在启动的时候声明说，“以我启动的时刻为准，如果一个数据版本是在我启动之前生成的，就认；如果是我启动以后才生成的，我就不认，我必须要找到它的上一个版本”。
在实现上， InnoDB 为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在“活跃”的所有事务 ID。“活跃”指的就是，启动了但还没提交。数组里面事务 ID 的最小值记为低水位，当前系统里面已经创建过的事务 ID 的最大值加 1 记为高水位。

# 一致性读 和 当前读
- 可重复读的核心就是一致性读（consistent read）;
- 而事务更新数据的时候，只能用当前读（current read）;
- 如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。
除了 update 语句外，select 语句如果加锁，也是当前读。

```mysql
# 读锁（S 锁，共享锁）
mysql> select k from t where id=1 lock in share mode;

# 写锁（X 锁，排他锁）
mysql> select k from t where id=1 for update;
```

# 读提交的逻辑和可重复读的逻辑类似，它们最主要的区别是：
- 在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图；
- 在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图。

SQL 标准的事务隔离级别包括：
- 读未提交（read uncommitted）      一个事务还没提交时，它做的变更就能被别的事务看到。
- 读提交（read committed）          一个事务提交之后，它做的变更才会被其他事务看到。
- 可重复读（repeatable read）       一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。
- 串行化（serializable ）           对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。

读未提交（脏读），读已提交（不可重复读），可重复读（幻读），串行化。

# 当出现死锁以后，有两种策略：
- 一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。
- 另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。正常情况下我们还是要采用第二种策略，即：主动死锁检测。
减少死锁的主要方向，就是控制访问相同资源的并发事务量。

# 为什么不直接更改磁盘中的数据，而要在内存中更改，然后还需要写日志，最后再落盘这么复杂？
1. 最主要就是性能问题。因为直接写磁盘文件是随机写，开销大性能低，没办法满足MySQL的性能要求。所以才会设计成先在内存中对数据进行更改，再异步落盘。但是内存总是不可靠，万一断电重启，还没来得及落盘的内存数据就会丢失，所以还需要加上写日志这个步骤，万一断电重启，还能通过日志中的记录进行恢复。
2. 写日志虽然也是写磁盘，但是它是顺序写，相比随机写开销更小，能提升语句执行的性能。
3. 这个技术就是大多数存储系统基本都会用的`WAL(Write Ahead Log)`技术，也称为日志先行的技术，指的是对数据文件进行修改前，必须将修改先记录日志。保证了数据一致性和持久性，并且提升语句执行性能。

# InnoDB 的锁
- 全局锁：就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL)，整个数据库进入只读状态。全局锁的典型使用场景是，做全库逻辑备份。官方自带的逻辑备份工具是 mysqldump。当 mysqldump 使用参数–single-transaction 的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 MVCC 的支持，这个过程中数据是可以正常更新的。
- 表级锁：一种是表锁，一种是元数据锁（meta data lock，MDL)。表锁（不是MDL）一般是在数据库引擎不支持行锁的时候才会被用到的。
  MDL 不需要显式使用，在访问一个表的时候会被自动加上。MDL 的作用是，保证读写的正确性。在 MySQL 5.5 版本中引入了 MDL，当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁。MDL 会直到事务提交才释放。
  - 读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。
  - 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。
- 行锁：在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是`两阶段锁协议`。如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。

# sql优化
建索引，修改sql，analyze table

# change buffer
主要用来优化写操作。

InnoDB 的数据是按数据页为单位来读写的。也就是说，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。在 InnoDB 中，每个数据页的大小默认是 16KB。

change buffer：
当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InnoDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。

将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 merge。merge 的时机:
- 访问这个数据页会触发 merge 
- 系统有后台线程会定期 merge
- 在数据库正常关闭（shutdown）的过程中，也会执行 merge 操作

对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。因此要读取数据页，没必要使用chang buffer。
因此，也只有普通索引可以使用change buffer。

使用场景：
对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在 change buffer，但之后由于马上要访问这个数据页，会立即触发 merge 过程。这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价。所以，对于这种业务模式来说，change buffer 反而起到了副作用。

这两类索引在查询能力上是没差别的，主要考虑的是对更新性能的影响。所以，我建议你尽量选择普通索引。
