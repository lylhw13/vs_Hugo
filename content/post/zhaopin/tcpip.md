---
title: "Tcpip"
date: 2020-06-14T10:20:09+08:00
draft: true
---




TCP 协议如何保证可靠传输
一、综述

1 确认和重传：接收方收到报文就会确认，发送方发送一段时间后没有收到确认就重传。

2 数据校验

3 数据合理分片和排序：

　　UDP：IP数据报大于1500字节,大于MTU.这个时候发送方IP层就需要分片(fragmentation).把数据报分成若干片,使每一片都小于MTU.而接收方IP层则需要进行数据报的重组.这样就会多做许多事情,而更严重的是,由于UDP的特性,当某一片数据传送中丢失时,接收方便无法重组数据报.将导致丢弃整个UDP数据报.

　　tcp会按MTU合理分片，接收方会缓存未按序到达的数据，重新排序后再交给应用层。

4 流量控制：当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。

5 拥塞控制：当网络拥塞时，减少数据的发送。


拥塞控制：拥塞控制是作用于网络的，它是防止过多的数据注入到网络中，避免出现网络负载过大的情况；常用的方法就是：1 慢开始、拥塞避免  2 快重传、快恢复。

流量控制：流量控制是作用于接收者的，它是控制发送者的发送速度从而使接收者来得及接收，防止分组丢失的。

（一）慢开始算法：

发送方维持一个叫做拥塞窗口cwnd（congestion window）的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口等于拥塞窗口，另外考虑到接受方的接收能力，发送窗口可能小于拥塞窗口。

慢开始算法的思路就是，不要一开始就发送大量的数据，先探测一下网络的拥塞程度，也就是说由小到大逐渐增加拥塞窗口的大小。

二）拥塞避免算法：

拥塞避免算法让拥塞窗口缓慢增长，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1，而不是加倍。这样拥塞窗口按线性规律缓慢增长

（三）快重传算法：

快重传要求接收方在收到一个失序的报文段后就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方，可提高网络吞吐量约20%）而不要等到自己发送数据时捎带确认。快重传算法规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期。

（四）快恢复算法：

快重传配合使用的还有快恢复算法，有以下两个要点：

当发送方连续收到三个重复确认时，就执行“乘法减小”算法，把ssthresh门限减半（为了预防网络发生拥塞）。但是接下去并不执行慢开始算法
考虑到如果网络出现拥塞的话就不会收到好几个重复的确认，所以发送方现在认为网络可能没有出现拥塞。所以此时不执行慢开始算法，而是将cwnd设置为ssthresh减半后的值，然后执行拥塞避免算法，使cwnd缓慢增大。

# 谈一下，tcp为什么要建立连接？

tcp是提供可靠性连接的，只有支持端到端的连接，才能进行可靠性传输，连接的主要功能在于记录两个端口间的通信状态，不连接则无法记录两个端口通信的状态，则无法知道丢失了哪个数据包，重复收到了哪个数据包，也无法确保数据包之间的到达顺序，还有很多增加可靠性的功能都无法应用。

# TCP协议保证数据传输可靠性的方式主要有：

1. 校验和
2. 序列号
3. 确认应答
4. 超时重传
5. 连接管理
6. 流量控制
7. 拥塞控制

如何减轻SYN洪水攻击？

- 增加积压队列
- 回收最早的半开TCP连接
- SYN cookie

# 半连接攻击 全连接攻击

tcp_syncookies

众所周知，tcp通信是一个面向连接的过程，客户端要和服务端连接，必须进行连接才能进行通信。在tcp连接中，有两种连接攻击方式，是半连接攻击机和全连接攻击。

<1>半连接攻击?

    半连接攻击是一种攻击协议栈的攻击方式，坦白说就是攻击主机的一种攻击方式。通过将主机的资源消耗殆尽，从而导致应用层的程序无资源可用，导致无法运行。在正常情况下，客户端连接服务端需要通过三次握手，首先客户端构造一个SYN连接数据包发送至服务端，自身进入SYN_SEND状态，当服务端收到客户端的SYN包之后，为其分配内存核心内存，并将其放置在半连接队列中，服务端接收客户SYN包并会向客户端发送一个SYN包和ACK包，此刻服务端进入SYN_RECV态。客户端收到包之后，再次向服务端发送ACK确认包。至此连接建立完成，双方都进入ESTABLSHEDZ状态。半连接就是通过不断地构造客户端的SYN连接数据包发向服务端，等到服务端的半连接队列满的时候，后续的正常用户的连接请求将会被丢弃，从而无法连接到服务端。此为半连接攻击方式。根据服务端的半连接队列的大小，不同主机的抵抗这种SYN攻击的能力也是不一样。

如何来解决半连接攻击？

可以通过拓展半连接队列的大小，来进行补救，但缺点是，不能无限制的增加，这样会耗费过多的服务端资源，导致服务端性能地下。这种方式几乎不可取。现主要通syn cookie或者syn中继机制来防范半连接攻，部位半连接分配核心内存的方式来防范。

<2>全连接攻击？

   全连接攻击是通过消费服务端进程数和连接数，只连接而不进行发送数据的一种攻击方式。当客户端连接到服务端，仅仅只是连接，此时服务端会为每一个连接创建一个进程来处理客户端发送的数据。但是客户端只是连接而不发送数据，此时服务端会一直阻塞在recv或者read的状态，如此一来，多个连接，服务端的每个连接都是出于阻塞状态从而导致服务端的崩溃。

如何来解决全连接攻击？

可以通过不为全连接分配进程处理的方式来防范全连接攻击，具体的情况是当收到数据之后，在为其分配一个处理线程。具体的处理方式在accept返回之前是不分配处理线程的。直到接收相关的数据之后才为之提供一个处理过程。例如在apache服务中，是通过预创建一定量的子进程作为处理连接继承。所有的自己进程都继承父进程的sockfd，每当有一个连接过来时，只有当accept返回是，才会为该链接分配一个进程来处理连接请求。负责，子进程一直处于等待状态。如果出现值是连接存在，而始终不放数据，该链接的状态是SYN_RECV，在协议栈中，提供一个保活期给该链接，如果超过保活期还没有数据到来，服务端协议栈将会断开该链接。如果没有该保活期，虽然避免了ESTABLESHED状态的数量，但是SYN_RECV的数据量的增长仍旧是不可估算的，所以需要利用保活期来监控该链接是需要清除断开。


# timewait过多
MSL：maximum segment lifetime, RFC 1122 的建议值是2分钟，源自Berkeley的实现是30秒。

有两个原因：一是对方连接出了问题，一是本机没有及时回收资源。
本机可以修改底层最大TIME_WAIT数量或者修改Time_wait时间。 复用。

# close_wait 过多

可能原因是服务器的socket没有关闭。
对于并发服务器，调用close函数只会使socket的引用计数值减1，并不会直接关闭socket。直到socket的引用计数为0才会相应关闭。如果某个进程一直不关闭它持有的socket，就会出现close_wait过多的情况。

调用shutdown函数可以直接关闭socket。

TCP 流量控制机制：滑动窗口，慢启动，拥塞避免，快速重传，快速恢复

# ping需要100ms 则从输入地址到返回页面需要多久？

三次握手 加 HTTP一去一回，一共2.5RTT，所以是250ms

# ip 寻址和mac寻址

虽然数据包发送时包含了完整的TCP/IP四层信息，但是IP地址只在网络间寻址才起作用，在同一个网络内，IP地址在发送端被转化为MAC地址进行寻址，而这种转化和交换的对应关系，依赖于ARP协议和MAC地址表。

二层基于MAC地址转发数据帧，三层基于IP地址转发报文。

# HTTPS 

1. 某网站拥有用于非对称加密的公钥A、私钥A’。
2. 浏览器像网站服务器请求，服务器把公钥A明文给传输浏览器。
3. 浏览器随机生成一个用于对称加密的密钥X，用公钥A加密后传给服务器。
4. 服务器拿到后用私钥A’解密得到密钥X。
5. 这样双方就都拥有密钥X了，且别人无法知道它。之后双方所有数据都用密钥X加密解密。

HTTPS 协议提供了三个关键的指标：
- 加密(Encryption)
- 数据一致性(Data integrity)
- 身份认证(Authentication)

# UDP 和 TCP 的数据包有最大长度限制吗？

MTU：maximum transmission unit 最大传输单元，以太网的MTU是1500字节
MSS：maximum segment size 最大分节大小，用于向对端TCP通告对端在每个分节中能发送的最大TCP数据量。
    MSS经常设置成MTU减去IP和TCP首部的固定长度。
    在以太网中使用IPv4的MSS值为 1460 = 1500 - 20 - 20；
    使用IPv6的MSS值为 1440 = 1500 - 20 - 40；

TCP 首部20字节
IPv4 首部20字节， IPv6 首部 40字节

所有标记`数据报大小`的字段长度都为 16位
IPv4 首部中是叫做`总长度`，IPv6 首部中叫做`净荷长度`。因此
IPv4数据报的最大大小是65535字节，包括IPv4首部。
IPv6数据报的最大大小是65535 + 40 字节即65575字节，包括40字节的IPv6首部。
对于内部的数据还要减去相应的TCP首部或者UDP首部。

UDP包分为包头和正文，　包头共有 64 位（8 字节），分别是 16 位源端口，16 位目的端口，16 位UDP包长度和 16 位校验和．因此UDP包正文的最大长度是２^16 - 1=65535字节。

# TCP 分段 和 IP 分段，UDP 会分段吗

TCP分段的原因是MSS，IP分片的原因是MTU，一般MSS经常设置成MTU减去IP和TCP首部的固定长度，因此也就不需要在网络层进行IP分片了。因此TCP报文段很少会发生IP分片的情况。

由于UDP数据报不会自己进行分段，因此当长度超过了MTU时，会在网络层进行IP分片。同样，ICMP（在网络层中）同样会出现IP分片情况。

总结：UDP不会分段，就由IP来分。TCP会分段，当然就不用IP来分了！

# TCP第三次握手失败后怎么办？

当客户端收到服务端的SYN+ACK应答后，其状态变为ESTABLISHED，并会发送ACK包给服务端，准备发送数据了。如果此时ACK在网络中丢失，过了超时计时器后，那么Server端会重新发送SYN+ACK包，重传次数根据/proc/sys/net/ipv4/tcp_synack_retries来指定，默认是5次。如果重传指定次数到了后，仍然未收到ACK应答，那么一段时间后，Server自动关闭这个连接。但是Client认为这个连接已经建立，如果Client端向Server写数据，Server端将以RST包响应，方能感知到Server的错误。

当失败时服务器并不会重传ack报文，而是直接发送RTS报文段，进入CLOSED状态。这样做的目的是为了防止SYN洪泛攻击。

# http 默认长链接

# TCP 连接数
作为客户端去连接，受到 fd 描述符，内存和port端口的限制。每一个tcp连接都要占一个文件描述符。
作为服务端接受连接，理论无上限。

# 传输层发生拥塞，在应用层的表现是什么
一般默认套接字是阻塞的，应用进程将被投入休眠。内核将不从 write 系统调用返回，直到应用进程缓冲区中的所有数据都复制到套接字发送缓冲区。

# 流量控制和拥塞控制


TCP在网络OSI的七层模型中的第四层——Transport层，IP在第三层——Network层，ARP在第二层——Data Link层，在第二层上的数据，我们叫Frame，在第三层上的数据叫Packet，第四层的数据叫Segment

# CDN
CDN，全称Content Delivery Network，主要作用是为源站减少访问压力的同时，为客户端提供更快速的内容响应。除此之外，CDN还能对源站进行安全防护。 

资源上传cdn之后，当用户访问cdn的资源地址之后会经历下面的步骤：
- 首先经过dns解析，请求cname指向cdn专用的dns服务器。
- dns服务器返回全局负载均衡的服务器ip给用户
- 用户请求区域负载均衡服务器，负载均衡服务器根据用户ip选择距离近的，并且存在用户所需内容的，负载比较合适的一台缓存服务器ip给用户。
  
当没有对应内容的时候，会去上一级缓存服务器去找，直到找到资源所在的源站服务器，并且缓存在缓存服务器中。用户下一次在请求该资源，就可以就近拿缓存了。
注意：因为cdn的负载均衡和就近选择缓存都是根据用户的ip来的，服务器只能拿到local dns的ip，也就是网络设置中设置的dns ip，如果这个设置的不合理，那么可能起不到加速的效果。可能就近找到的缓存服务器实际离得很远。

# connect对于udp的作用
1. 再也不能给输出操作指定IP地址和端口号，不能使用sendto，而改用write或send。写到已连接UDP套接字上的任何内容都自动发送到connet指定到地址。
2. 不必使用recvfrom以获悉数据报到发送者，而改用read，recv或recvmsg。
3. 由已连接UDP套接字引发的异步错误会返回给它们所在的进程，而未连接的UDP套接字不接受任何异步错误。

# NAT
NAT（Network Address Translation，网络地址转换），也叫做网络掩蔽或者IP掩蔽。NAT是一种网络地址翻译技术，主要是将内部的私有IP地址（private IP）转换成可以在公网使用的公网IP（public IP）。

NAT主要有种类型：
- 静态NAT(Static NAT)
- 网络地址端口转换（NAPT） 端口多路复用技术。与静态NAT的差别是，NAPT不但要转换IP地址，还要进行传输层的端口转换。

NAT主要可以实现以下几个功能：数据包伪装、负载均衡、端口转发和透明代理。

# 如果client已经退出，此时服务端继续send会出现什么问题

第一次向已关闭的socket写操作会引发RST。
向已收到RST的套接字执行写操作时，内核将向该进程发送一个SIGPIPE信号。该信号的默认行为是终止进程，因此进程必须捕获它以免被不情愿的终止。

# cookie 和 session

cookie机制采用的是在客户端保持状态的方案。它是在用户端的会话状态的存贮机制，他需要用户打开客户端的cookie支持。cookie的作用就是为了解决HTTP协议无状态的缺陷所作的努力。

session机制是一种服务器端的机制，服务器使用一种类似于散列表的结构（也可能就是使用散列表）来保存信息。

当程序需要为某个客户端的请求创建一个session时，服务器首先检查这个客户端的请求里是否已包含了一个session标识（称为session id），如果已包含则说明以前已经为此客户端创建过session，服务器就按照session id把这个session检索出来使用（检索不到，会新建一个），如果客户端请求不包含session id，则为此客户端创建一个session并且生成一个与此session相关联的session id，session id的值应该是一个既不会重复，又不容易被找到规律以仿造的字符串，这个session id将被在本次响应中返回给客户端保存。

1. cookie数据存放在客户的浏览器上，session数据放在服务器上
2. cookie不是很安全，别人可以分析存放在本地的COOKIE并进行COOKIE欺骗,如果主要考虑到安全应当使用session
3. session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能，如果主要考虑到减轻服务器性能方面，应当使用COOKIE
4. 单个cookie在客户端的限制是3K，就是说一个站点在客户端存放的COOKIE不能3K。

# get 和 post 区别

GET 用于获取信息，无副作用的，是幂等的，且可缓存
POST 用于修改服务器上的数据，有副作用，非幂等，不可缓存

一个HTTP方法是幂等的，指的是同样的请求被执行一次与连续执行多次的效果是一样的，服务器的状态也是一样的。换句话说就是，幂等方法不应该具有副作用（统计用途除外）。在正确实现的条件下，GET，HEAD，PUT和DELETE 等方法都是幂等的，而 POST 方法不是。所有的 safe 方法也都是幂等的。

# ping的原理

# CGI

早期的Web服务器，只能响应浏览器发来的HTTP静态资源的请求，并将存储在服务器中的静态资源返回给浏览器。随着Web技术的发展，逐渐出现了动态技术，但是Web服务器并不能够直接运行动态脚本，为了解决Web服务器与外部应用程序（CGI程序）之间数据互通，于是出现了CGI（Common Gateway Interface）通用网关接口。简单理解，可以认为CGI是Web服务器和运行其上的应用程序进行“交流”的一种约定。

CGI是Web服务器和一个独立的进程之间的协议，它会把HTTP请求Request的Header头设置成进程的环境变量，HTTP请求的Body正文设置成进程的标准输入，进程的标准输出设置为HTTP响应Response，包含Header头和Body正文。

- CGI程序的工作原理
Web服务器一般只用来处理静态文件请求，一旦碰到动态脚本请求，Web服务器主进程就会Fork创建出一个新的进程来启动CGI程序，也就是将动态脚本交给CGI程序来处理。启动CGI程序需要一个过程，如读取配置文件、加载扩展等。当CGI程序启动后会去解析动态脚本，然后将结果返回给Web服务器，最后由Web服务器将结果返回给客户端，之前Fork出来的进程也随之关闭。这样，每次用户请求动态脚本，Web服务器都要重新Fork创建一个新进程去启动CGI程序，由CGI程序来处理动态脚本，处理完成后进程随之关闭